{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adminroot/miniconda3/envs/distill_data/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=datasets.FashionMNIST(\n",
    "    root=\"fun_data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root=\"fun_data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(training_data,batch_size=64,shuffle=True)\n",
    "test_dataloader=DataLoader(test_data,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp=next(iter(train_dataloader))\n",
    "tmp[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model=NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     initial_lr: 0.01\n",
       "     lr: 0.01\n",
       "     maximize: False\n",
       "     momentum: 0.9\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " <torch.optim.lr_scheduler.ExponentialLR at 0x7fb35bd7e550>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\n",
    "scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.9)\n",
    "optimizer,scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,model,loss_fn,optimizer):\n",
    "    size=len(dataloader.dataset)\n",
    "    model.train()\n",
    "    #model train is set for batch normalization\n",
    "    #and dropout layers\n",
    "    for batch,(x,y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        pred=model(x)\n",
    "        loss=loss_fn(pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch%100==0:\n",
    "            loss,current=loss.item(),(batch+1)*len(x)\n",
    "            print(f\"loss: {loss} [{current}/{size}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader,model,loss_fn):\n",
    "    model.eval()\n",
    "    size=len(dataloader.dataset) #all data\n",
    "    num_batches=len(dataloader) # num of batch\n",
    "    test_loss,correct=0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            pred=model(x)\n",
    "            test_loss+=loss_fn(pred,y).item()\n",
    "            correct+=(pred.argmax(1)==y).sum().item()\n",
    "    test_loss/=num_batches\n",
    "    correct/=size\n",
    "    print(f\"test error: \\n Accuracy: {100*correct}, Avg loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1\n",
      "----------------------\n",
      "loss: 2.299267053604126 [64/60000]\n",
      "loss: 0.7538191676139832 [6464/60000]\n",
      "loss: 0.6451717019081116 [12864/60000]\n",
      "loss: 0.5404155850410461 [19264/60000]\n",
      "loss: 0.5290641784667969 [25664/60000]\n",
      "loss: 0.5158385038375854 [32064/60000]\n",
      "loss: 0.4327242970466614 [38464/60000]\n",
      "loss: 0.542901337146759 [44864/60000]\n",
      "loss: 0.39552080631256104 [51264/60000]\n",
      "loss: 0.6330477595329285 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 81.11, Avg loss: 0.5267184053067189\n",
      "Epochs 2\n",
      "----------------------\n",
      "loss: 0.29002639651298523 [64/60000]\n",
      "loss: 0.47462591528892517 [6464/60000]\n",
      "loss: 0.6206664443016052 [12864/60000]\n",
      "loss: 0.43456897139549255 [19264/60000]\n",
      "loss: 0.33329957723617554 [25664/60000]\n",
      "loss: 0.42221033573150635 [32064/60000]\n",
      "loss: 0.3988877236843109 [38464/60000]\n",
      "loss: 0.31969013810157776 [44864/60000]\n",
      "loss: 0.39035317301750183 [51264/60000]\n",
      "loss: 0.33082470297813416 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 84.82, Avg loss: 0.4130552054210833\n",
      "Epochs 3\n",
      "----------------------\n",
      "loss: 0.19797344505786896 [64/60000]\n",
      "loss: 0.3331459164619446 [6464/60000]\n",
      "loss: 0.3339759409427643 [12864/60000]\n",
      "loss: 0.39848411083221436 [19264/60000]\n",
      "loss: 0.38878458738327026 [25664/60000]\n",
      "loss: 0.2322618067264557 [32064/60000]\n",
      "loss: 0.3165991008281708 [38464/60000]\n",
      "loss: 0.3620288372039795 [44864/60000]\n",
      "loss: 0.43145886063575745 [51264/60000]\n",
      "loss: 0.3243216872215271 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 85.8, Avg loss: 0.3912929012707085\n",
      "Epochs 4\n",
      "----------------------\n",
      "loss: 0.2538891136646271 [64/60000]\n",
      "loss: 0.3980766534805298 [6464/60000]\n",
      "loss: 0.3776247501373291 [12864/60000]\n",
      "loss: 0.247815802693367 [19264/60000]\n",
      "loss: 0.3686692714691162 [25664/60000]\n",
      "loss: 0.2139945924282074 [32064/60000]\n",
      "loss: 0.322918564081192 [38464/60000]\n",
      "loss: 0.39606934785842896 [44864/60000]\n",
      "loss: 0.21650946140289307 [51264/60000]\n",
      "loss: 0.3944523334503174 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 86.7, Avg loss: 0.3636619733397368\n",
      "Epochs 5\n",
      "----------------------\n",
      "loss: 0.2236895114183426 [64/60000]\n",
      "loss: 0.334688663482666 [6464/60000]\n",
      "loss: 0.25434166193008423 [12864/60000]\n",
      "loss: 0.236564040184021 [19264/60000]\n",
      "loss: 0.17860251665115356 [25664/60000]\n",
      "loss: 0.33311033248901367 [32064/60000]\n",
      "loss: 0.18132451176643372 [38464/60000]\n",
      "loss: 0.2036053091287613 [44864/60000]\n",
      "loss: 0.41595643758773804 [51264/60000]\n",
      "loss: 0.46682021021842957 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 86.47, Avg loss: 0.36998328822813215\n",
      "Epochs 6\n",
      "----------------------\n",
      "loss: 0.20481863617897034 [64/60000]\n",
      "loss: 0.4935482144355774 [6464/60000]\n",
      "loss: 0.32553747296333313 [12864/60000]\n",
      "loss: 0.3769857883453369 [19264/60000]\n",
      "loss: 0.37341752648353577 [25664/60000]\n",
      "loss: 0.19844305515289307 [32064/60000]\n",
      "loss: 0.23448042571544647 [38464/60000]\n",
      "loss: 0.21967056393623352 [44864/60000]\n",
      "loss: 0.20631027221679688 [51264/60000]\n",
      "loss: 0.247078076004982 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 87.06, Avg loss: 0.35134293053560195\n",
      "Epochs 7\n",
      "----------------------\n",
      "loss: 0.23500490188598633 [64/60000]\n",
      "loss: 0.24610452353954315 [6464/60000]\n",
      "loss: 0.13538913428783417 [12864/60000]\n",
      "loss: 0.2542848587036133 [19264/60000]\n",
      "loss: 0.16497047245502472 [25664/60000]\n",
      "loss: 0.355525940656662 [32064/60000]\n",
      "loss: 0.19793760776519775 [38464/60000]\n",
      "loss: 0.1279071718454361 [44864/60000]\n",
      "loss: 0.1769045740365982 [51264/60000]\n",
      "loss: 0.3246949315071106 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 87.79, Avg loss: 0.3399779813684476\n",
      "Epochs 8\n",
      "----------------------\n",
      "loss: 0.1677524298429489 [64/60000]\n",
      "loss: 0.34932732582092285 [6464/60000]\n",
      "loss: 0.23572872579097748 [12864/60000]\n",
      "loss: 0.31042221188545227 [19264/60000]\n",
      "loss: 0.2652810215950012 [25664/60000]\n",
      "loss: 0.17993248999118805 [32064/60000]\n",
      "loss: 0.25884950160980225 [38464/60000]\n",
      "loss: 0.27157407999038696 [44864/60000]\n",
      "loss: 0.3219470679759979 [51264/60000]\n",
      "loss: 0.31559455394744873 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 88.02, Avg loss: 0.3456973896664419\n",
      "Epochs 9\n",
      "----------------------\n",
      "loss: 0.22613123059272766 [64/60000]\n",
      "loss: 0.3801768124103546 [6464/60000]\n",
      "loss: 0.3448108732700348 [12864/60000]\n",
      "loss: 0.3496721684932709 [19264/60000]\n",
      "loss: 0.14771369099617004 [25664/60000]\n",
      "loss: 0.34513625502586365 [32064/60000]\n",
      "loss: 0.32792508602142334 [38464/60000]\n",
      "loss: 0.24418507516384125 [44864/60000]\n",
      "loss: 0.4742615520954132 [51264/60000]\n",
      "loss: 0.1424477994441986 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 88.06, Avg loss: 0.33198266704181195\n",
      "Epochs 10\n",
      "----------------------\n",
      "loss: 0.23570847511291504 [64/60000]\n",
      "loss: 0.26766276359558105 [6464/60000]\n",
      "loss: 0.198589488863945 [12864/60000]\n",
      "loss: 0.26558324694633484 [19264/60000]\n",
      "loss: 0.17375397682189941 [25664/60000]\n",
      "loss: 0.26406723260879517 [32064/60000]\n",
      "loss: 0.34820759296417236 [38464/60000]\n",
      "loss: 0.18884103000164032 [44864/60000]\n",
      "loss: 0.17119158804416656 [51264/60000]\n",
      "loss: 0.18473362922668457 [57664/60000]\n",
      "test error: \n",
      " Accuracy: 88.35, Avg loss: 0.32839472055625\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epochs {t+1}\\n----------------------\")\n",
    "    train(train_dataloader,model,loss_fn,optimizer)\n",
    "    test(test_dataloader,model,loss_fn)\n",
    "    scheduler.step()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading time without mmap=0.00666499137878418\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "state_dict=torch.load('checkpoint.pth')\n",
    "end_time=time.time()\n",
    "print(f\"loading time without mmap={end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading time with the mmap=0.004232883453369141\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "state_dict=torch.load('checkpoint.pth',mmap=True)\n",
    "end_time=time.time()\n",
    "print(f\"loading time with the mmap={end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distill_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
